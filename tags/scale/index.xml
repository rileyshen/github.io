<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scale on Website of Riley</title>
    <link>https://rileyshen.github.io/tags/scale/</link>
    <description>Recent content in scale on Website of Riley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 01 Mar 2022 15:56:39 +0800</lastBuildDate><atom:link href="https://rileyshen.github.io/tags/scale/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>learning System design as a landscape architect 6</title>
      <link>https://rileyshen.github.io/post/sys6/</link>
      <pubDate>Tue, 01 Mar 2022 15:56:39 +0800</pubDate>
      
      <guid>https://rileyshen.github.io/post/sys6/</guid>
      
        <description>&lt;p&gt;Rethink system design in a much fun way, as a former urban planner/landscape planner. Take Scale and Distributed File System Desig as example&lt;/p&gt;
&lt;!-- more --&gt;
&lt;!-- TOC --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#problem-based-learning-to-understand-scale&#34; &gt;Problem-based learning to understand SCALE&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#mysql-replica&#34; &gt;MySQL Replica&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#master-slave-replica&#34; &gt;Master Slave Replica&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#write-ahead-log&#34; &gt;Write Ahead Log&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-if-the-master-crash&#34; &gt;What if the Master crash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nosql-replica&#34; &gt;NoSQL Replica&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sql-vs-nosql&#34; &gt;SQL vs NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#user-table-sharding&#34; &gt;User Table Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#friendship-table-sharding&#34; &gt;Friendship Table Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessopm-table-sharding&#34; &gt;Sessopm Table Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#news-feed--timeline-sharding&#34; &gt;News Feed / Timeline Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#leetcode-submission-sharding&#34; &gt;leetcode Submission Sharding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#problem-based-learning-to-understand-distributed-file-system&#34; &gt;Problem-based learning to understand Distributed File System&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-analysis&#34; &gt;Scenario analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#basic-function&#34; &gt;basic function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#service-analysis&#34; &gt;Service analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stroage&#34; &gt;Stroage&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-design-gfs-global-file-system&#34; &gt;How to design GFS Global File System&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-write-a-file&#34; &gt;how to write a file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-modify-the-written-file&#34; &gt;how to modify the written file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-read-a-file&#34; &gt;how to read a file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#master-task&#34; &gt;Master Task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-work-solution&#34; &gt;One Work Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-identify-whether-a-chunk-on-the-disk-is-broken&#34; &gt;How to identify whether a chunk on the disk is broken&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-avoid-chunk-data-loss-when-a-chunkserver-is-down&#34; &gt;How to avoid chunk data loss when a ChunkServer is down&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#design-a-lookup-service&#34; &gt;Design a lookup service&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#senorio&#34; &gt;senorio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#service&#34; &gt;service&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /TOC --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;problem-based-learning-to-understand-scale&#34;&gt;Problem-based learning to understand SCALE&lt;/h2&gt;
&lt;p&gt;&lt;a id=&#34;markdown-problem-based-learning-to-understand-scale&#34; name=&#34;problem-based-learning-to-understand-scale&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.How to scale system ≈ How to scale database&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2.single point failure&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;3.Replica (3 times)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;4.Vertical Sharding (cons: massive data and QPS with few column)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Consistent Hashing&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;0 - 2^64 - 1 &amp;ndash;&amp;gt; large Ring&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Virtual Node&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;mysql-replica&#34;&gt;MySQL Replica&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-mysql-replica&#34; name=&#34;mysql-replica&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;master-slave-replica&#34;&gt;Master Slave Replica&lt;/h4&gt;
&lt;p&gt;&lt;a id=&#34;markdown-master-slave-replica&#34; name=&#34;master-slave-replica&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&#34;write-ahead-log&#34;&gt;Write Ahead Log&lt;/h5&gt;
&lt;p&gt;&lt;a id=&#34;markdown-write-ahead-log&#34; name=&#34;write-ahead-log&#34;&gt;&lt;/a&gt;
• Any operation of the SQL database will be recorded in the form of &lt;strong&gt;Log&lt;/strong&gt;
• For example, data A is changed from C to D at time B
• After the slave is activated, tell the master that I am there
• &lt;strong&gt;The master notifies the slave to read the log every time there is any operation&lt;/strong&gt;
• So the data on the slave is &amp;ldquo;delayed&amp;rdquo;&lt;/p&gt;
&lt;h5 id=&#34;what-if-the-master-crash&#34;&gt;What if the Master crash&lt;/h5&gt;
&lt;p&gt;&lt;a id=&#34;markdown-what-if-the-master-crash&#34; name=&#34;what-if-the-master-crash&#34;&gt;&lt;/a&gt;
• Upgrade a Slave to Master, accept read+write
• There may be some degree of data loss and inconsistency&lt;/p&gt;
&lt;h3 id=&#34;nosql-replica&#34;&gt;NoSQL Replica&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-nosql-replica&#34; name=&#34;nosql-replica&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cassandra : data is stored &amp;ldquo;clockwise&amp;rdquo; in three virtual groups on the Consistent hashing ring
in nodes&lt;/p&gt;
&lt;h3 id=&#34;sql-vs-nosql&#34;&gt;SQL vs NoSQL&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-sql-vs-nosql&#34; name=&#34;sql-vs-nosql&#34;&gt;&lt;/a&gt;
The &amp;ldquo;auto&amp;rdquo; Replica method is the Master Slave
The &amp;ldquo;manual&amp;rdquo; Replica method can also deposit three copies clockwise on the Consistent Hashing ring&lt;/p&gt;
&lt;p&gt;The &amp;ldquo;auto&amp;rdquo; Replica way is to store three copies clockwise on the Consistent Hashing ring
The &amp;ldquo;manual&amp;rdquo; Replica way: No need to do it manually&lt;/p&gt;
&lt;h3 id=&#34;user-table-sharding&#34;&gt;User Table Sharding&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-user-table-sharding&#34; name=&#34;user-table-sharding&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;SQL data &amp;ndash; &amp;gt; User Table&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to shard data based on how to query data&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from user_table where user_id=xxx&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;use user_id&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After User Table Sharding, what if multiple databases cannot maintain a global auto-increment ID?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Manually create a UUID as the user&amp;rsquo;s user_id&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;When a user is created, there is no user_id of the user, which database to create this user?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Web Server is responsible for creating the user&amp;rsquo;s UUID as user_id&lt;/li&gt;
&lt;li&gt;After creation, obtain the entity database information based on the result of consistent_hash(user_id)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;what if the User Table has used auto-incrementing IDs before sharding?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;UUID is usually a string, and the auto-incrementing id is an integer, which is not compatible&lt;/li&gt;
&lt;li&gt;A separate global UserIdService is used to create a new user IDs, record the maximum value of the current UserId, increasing + 1 everytime. It would ensure the atomicity of data operations (Atomic).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;friendship-table-sharding&#34;&gt;Friendship Table Sharding&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-friendship-table-sharding&#34; name=&#34;friendship-table-sharding&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;direacted: to_userid&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;undirected friendship: need store 2 datas, use a as sharding key, and use b as sharding key&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;sessopm-table-sharding&#34;&gt;Sessopm Table Sharding&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-sessopm-table-sharding&#34; name=&#34;sessopm-table-sharding&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;session_key&lt;/strong&gt; as sharding key&lt;/p&gt;
&lt;h3 id=&#34;news-feed--timeline-sharding&#34;&gt;News Feed / Timeline Sharding&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-news-feed-%2F-timeline-sharding&#34; name=&#34;news-feed-%2F-timeline-sharding&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;user_id&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;leetcode-submission-sharding&#34;&gt;leetcode Submission Sharding&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-leetcode-submission-sharding&#34; name=&#34;leetcode-submission-sharding&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;demand1： query certain question submit records&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from submission_table where problem_id=100;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;demand2: query certain user submit records&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from submission_table where user_id=101;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;how to meet two demands? since NoSQL is not support multi-index&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;use user_id as sharding key in the submission_table&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create the second table, store all the submission of certain question&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;table contains &amp;ldquo;problem_id, submission_id&amp;hellip;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use problem_id as sharding key&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;problem-based-learning-to-understand-distributed-file-system&#34;&gt;Problem-based learning to understand Distributed File System&lt;/h2&gt;
&lt;p&gt;&lt;a id=&#34;markdown-problem-based-learning-to-understand-distributed-file-system&#34; name=&#34;problem-based-learning-to-understand-distributed-file-system&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;scenario-analysis&#34;&gt;Scenario analysis&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-scenario-analysis&#34; name=&#34;scenario-analysis&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;basic-function&#34;&gt;basic function&lt;/h4&gt;
&lt;p&gt;&lt;a id=&#34;markdown-basic-function&#34; name=&#34;basic-function&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;function 1&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;user read and write file&lt;/li&gt;
&lt;li&gt;the size of files&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;function 2&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;how many machines needed to store those files&lt;/li&gt;
&lt;li&gt;the numbers of the mathines&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;service-analysis&#34;&gt;Service analysis&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-service-analysis&#34; name=&#34;service-analysis&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Server&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Server: Master-Slave&lt;/p&gt;
&lt;h3 id=&#34;stroage&#34;&gt;Stroage&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-stroage&#34; name=&#34;stroage&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;how-to-design-gfs-global-file-system&#34;&gt;How to design GFS (Global File System)&lt;/h4&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-design-gfs-global-file-system&#34; name=&#34;how-to-design-gfs-global-file-system&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to save a file in one machine? (100 G)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Metadata&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;File info&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Name=xxx.mp4&lt;/li&gt;
&lt;li&gt;CreatedTime=xxxxx&lt;/li&gt;
&lt;li&gt;Size=aaaaa&lt;/li&gt;
&lt;li&gt;index&lt;/li&gt;
&lt;li&gt;Block 11 -&amp;gt; diskOffset1&lt;/li&gt;
&lt;li&gt;Block 12 -&amp;gt; diskOffset2&lt;/li&gt;
&lt;li&gt;Block 13 -&amp;gt; diskOffset3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1 block = 4096Byte&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to save a file in one machine? (100 T)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;1 block = 64M = 64 * 1024k&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantage&lt;/strong&gt;
• Reduce size of metadata
• Reduce traffic&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantage&lt;/strong&gt;
• Waste space for small files&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Metadata&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;File info&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Name=xxx.mp4&lt;/li&gt;
&lt;li&gt;CreatedTime=xxxxx&lt;/li&gt;
&lt;li&gt;Size=aaaaa&lt;/li&gt;
&lt;li&gt;index&lt;/li&gt;
&lt;li&gt;Chunk 11 -&amp;gt; diskOffset1&lt;/li&gt;
&lt;li&gt;Chunk 12 -&amp;gt; diskOffset2&lt;/li&gt;
&lt;li&gt;Chunk 13 -&amp;gt; diskOffset3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;How to save extra-large file in several machine (10P)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;One master + many ChunkSer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Slave Servers = Chunk Servers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantage&lt;/strong&gt;
• Reduce size of metadata
• Reduce traffic&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantage&lt;/strong&gt;
• Waste space for small files&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Metadata&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;File info&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Name=xxx.mp4&lt;/li&gt;
&lt;li&gt;CreatedTime=xxxxx&lt;/li&gt;
&lt;li&gt;Size=aaaaa&lt;/li&gt;
&lt;li&gt;index&lt;/li&gt;
&lt;li&gt;Chunk 11 -&amp;gt; diskOffset1&lt;/li&gt;
&lt;li&gt;Chunk 12 -&amp;gt; diskOffset2&lt;/li&gt;
&lt;li&gt;Chunk 13 -&amp;gt; diskOffset3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;improve the performance&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;The master don’t record the diskOffset of a chunk&lt;/strong&gt;
Advantage&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reduce the size of metadata in master&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reduce the traffic between master and ChunkServer (chunk offset change won&amp;rsquo;t notify the master)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Metadata&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;File info&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Name=xxx.mp4&lt;/li&gt;
&lt;li&gt;CreatedTime=xxxxx&lt;/li&gt;
&lt;li&gt;Size=aaaaa&lt;/li&gt;
&lt;li&gt;index&lt;/li&gt;
&lt;li&gt;Chunk 11 -&amp;gt; cs3&lt;/li&gt;
&lt;li&gt;Chunk 12 -&amp;gt; cs3&lt;/li&gt;
&lt;li&gt;Chunk 13 -&amp;gt; cs4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;How much space to store 10P big file in metadata&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1 chunk = 64MB needs 64B&lt;/p&gt;
&lt;p&gt;10P needs 10G&lt;/p&gt;
&lt;h3 id=&#34;how-to-write-a-file&#34;&gt;how to write a file&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-write-a-file&#34; name=&#34;how-to-write-a-file&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It is not easy to keep all those replicas consistent.&lt;/p&gt;
&lt;p&gt;client &amp;ndash;&amp;gt; write File_name=/xxxx.mp4, Chunk index=1 &amp;ndash;&amp;gt; master&lt;/p&gt;
&lt;p&gt;master &amp;ndash;&amp;gt; Assign Chunkserver_locations=US, CS1 &amp;mdash;&amp;gt; client&lt;/p&gt;
&lt;p&gt;client &amp;ndash;&amp;gt; transfer data=/xxxx.mp4, Chunk index=1 &amp;ndash;&amp;gt; chunkServer1&lt;/p&gt;
&lt;p&gt;chunkServer1 &amp;ndash;&amp;gt; write finish&lt;/p&gt;
&lt;h3 id=&#34;how-to-modify-the-written-file&#34;&gt;how to modify the written file&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-modify-the-written-file&#34; name=&#34;how-to-modify-the-written-file&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;delete the file, then rewrite the file&lt;/p&gt;
&lt;h3 id=&#34;how-to-read-a-file&#34;&gt;how to read a file&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-read-a-file&#34; name=&#34;how-to-read-a-file&#34;&gt;&lt;/a&gt;
Split a file into multiple chunks to read&lt;/p&gt;
&lt;p&gt;client &amp;ndash;&amp;gt;  File_name=/xxxx.mp4 &amp;ndash;&amp;gt; master&lt;/p&gt;
&lt;p&gt;master &amp;ndash;&amp;gt; return a chunk list &amp;mdash;&amp;gt; client&lt;/p&gt;
&lt;p&gt;client &amp;ndash;&amp;gt; Read /xxxx.mp4 in chunkServer1 &amp;ndash;&amp;gt; chunkServer1&lt;/p&gt;
&lt;p&gt;chunkServer1 &amp;ndash;&amp;gt; Return data /xxxx.mp4-00-of-09&lt;/p&gt;
&lt;h3 id=&#34;master-task&#34;&gt;Master Task&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-master-task&#34; name=&#34;master-task&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Store each file&amp;rsquo;s metadata&lt;/li&gt;
&lt;li&gt;Store Map(file name + chunk index -&amp;gt; chunk server)
&lt;ul&gt;
&lt;li&gt;Find the corresponding chunkserver when reading&lt;/li&gt;
&lt;li&gt;Allocate free chunkservers when writing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;one-work-solution&#34;&gt;One Work Solution&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-one-work-solution&#34; name=&#34;one-work-solution&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;storage
&lt;ul&gt;
&lt;li&gt;Ordinary file system Meta Data, Block&lt;/li&gt;
&lt;li&gt;Large file storage: Block-&amp;gt; Chunk&lt;/li&gt;
&lt;li&gt;Large files on multiple machines: Chunk Server + Master&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;write
&lt;ul&gt;
&lt;li&gt;Master + Client + ChunkServer communication process&lt;/li&gt;
&lt;li&gt;Master maintains metadata and chunkserver tables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;read
&lt;ul&gt;
&lt;li&gt;Master + Client + ChunkServer communication process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-to-identify-whether-a-chunk-on-the-disk-is-broken&#34;&gt;How to identify whether a chunk on the disk is broken&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-identify-whether-a-chunk-on-the-disk-is-broken&#34; name=&#34;how-to-identify-whether-a-chunk-on-the-disk-is-broken&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;use &lt;strong&gt;CheckSum&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;how-to-avoid-chunk-data-loss-when-a-chunkserver-is-down&#34;&gt;How to avoid chunk data loss when a ChunkServer is down&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-how-to-avoid-chunk-data-loss-when-a-chunkserver-is-down&#34; name=&#34;how-to-avoid-chunk-data-loss-when-a-chunkserver-is-down&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Repica&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Repica&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3 replicas by default&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reliability: tolerate 2 failures&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HDFS&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Namenode actively monitors the numbers of replicas of each block. When a replica of a block is lost due to DataNode failure or disk failure, the NameNode creates another replica of the block.&lt;/p&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;p&gt;Master-Slave&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Storage
&lt;ul&gt;
&lt;li&gt;Save a file in one machine -&amp;gt; a big file in one machine -&amp;gt; a extra big file in multi-machine&lt;/li&gt;
&lt;li&gt;Multi-machine
&lt;ul&gt;
&lt;li&gt;How to use the master&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;How to traffic and storage of master?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Read
&lt;ul&gt;
&lt;li&gt;The process of reading a file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Write:
&lt;ul&gt;
&lt;li&gt;The process of writing a file&lt;/li&gt;
&lt;li&gt;How to reduce master traffic?
&lt;ul&gt;
&lt;li&gt;Client and Chunk Server coummunicate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How to reduce client traffic?
&lt;ul&gt;
&lt;li&gt;Leader Election&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Failure and Recover (key)
&lt;ul&gt;
&lt;li&gt;Discover the failure a chunk?
&lt;ul&gt;
&lt;li&gt;Check Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Avoid the failure a chunk?
&lt;ul&gt;
&lt;li&gt;Replica&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Recover the failure?
&lt;ul&gt;
&lt;li&gt;Ask master&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Discover the failure of the chunkserver?
&lt;ul&gt;
&lt;li&gt;Heart Beat (chunkservers-&amp;gt;master)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve the failure of writing ChunkServer?
&lt;ul&gt;
&lt;li&gt;etry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;design-a-lookup-service&#34;&gt;Design a lookup service&lt;/h2&gt;
&lt;p&gt;&lt;a id=&#34;markdown-design-a-lookup-service&#34; name=&#34;design-a-lookup-service&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;10 Billion key-value pair in this system, when the user enter the key, it return its value. Each key size is 0.1KB, each value is 1kb. Required QPS &amp;gt;= 5000, latency &amp;lt; 200ms&lt;/p&gt;
&lt;p&gt;Server Parameters need to know:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;commodity server&lt;/li&gt;
&lt;li&gt;8x cpu cores on each server&lt;/li&gt;
&lt;li&gt;32 G memory&lt;/li&gt;
&lt;li&gt;6T disk&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;solution step1: calcution&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;total key size 1 TB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;total value size 10T&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;with 6T disk, a server with two disks will be enough (12T)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1TB = 1024 GB ~ 1000 GB, 40 servers can store the whole keys.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;step2:  Find out the server location of the key&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For every request, 1 value, which is 1KB needs to be returned&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;total time for reading one value would be 10ms(disk seek) + 1KB/1MB * 30MS (reading 1kb sequentially form disk) ~ 10ms&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;add a location mapping, one is 8 bite, so the size of key + location ~ 1KB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;40 servers can store &amp;lt;key, disk-address&amp;gt; pairs in its memory (1TB memory size as a whole)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;binary search 30 times on memory, which can be ignored&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;total latency is 10 + 0.5 = 10.5 ms&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;step3: solve 5000 QPS demand&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;40 servers, each machine has 2 disk, one disk support for 100 times search, each server can support 200 operation.&lt;/li&gt;
&lt;li&gt;total QPS = 200 * 40 = 8000 &amp;gt; 5000&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;senorio&#34;&gt;senorio&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-senorio&#34; name=&#34;senorio&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;function demand:
search, read&lt;/p&gt;
&lt;p&gt;qps &amp;gt;= 5000&lt;/p&gt;
&lt;p&gt;read:&lt;/p&gt;
&lt;h3 id=&#34;service&#34;&gt;service&lt;/h3&gt;
&lt;p&gt;&lt;a id=&#34;markdown-service&#34; name=&#34;service&#34;&gt;&lt;/a&gt;
QPS&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>